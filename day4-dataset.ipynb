{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "from itertools import chain\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from utils.data import pad_ids, truncate_sequences\n",
    "from utils.dataset_walker import DatasetWalker\n",
    "from utils.knowledge_reader import KnowledgeReader\n",
    "\n",
    "from dataset import BaseDataset, SPECIAL_TOKENS\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    GPT2DoubleHeadsModel,\n",
    "    GPT2LMHeadModel,\n",
    "    PreTrainedModel,\n",
    "    PreTrainedTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track 1: Knowledge Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnowledgeSelectionDataset(BaseDataset):\n",
    "    def __init__(self, args, tokenizer, split_type, labels=True, labels_file=None):\n",
    "        super(KnowledgeSelectionDataset, self).__init__(args, tokenizer, split_type, labels, labels_file)\n",
    "        if self.args.negative_sample_method not in [\"all\", \"mix\", \"oracle\"]:\n",
    "            raise ValueError(\"negative_sample_method must be all, mix, or oracle, got %s\" % self.args.negative_sample_method)\n",
    "\n",
    "    def _knowledge_to_string(self, doc, name=\"\"):\n",
    "        join_str = \" %s \" % self.knowledge_sep_token\n",
    "        return join_str.join([name, doc[\"title\"], doc[\"body\"]])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        example = self.examples[index]\n",
    "\n",
    "        this_inst = {\n",
    "            \"dialog_id\": example[\"dialog_id\"],\n",
    "            \"input_ids\": [],\n",
    "            \"token_type_ids\": [],\n",
    "            \"mc_token_ids\": []\n",
    "        }\n",
    "\n",
    "        if self.split_type != \"train\":\n",
    "            # if eval_all_snippets is set, we use all snippets as candidates\n",
    "            if self.args.eval_all_snippets:\n",
    "                candidates = list(self.snippets.keys())\n",
    "            else:\n",
    "                candidates = example[\"candidates\"]\n",
    "        else:\n",
    "            if self.args.negative_sample_method == \"all\":\n",
    "                candidates = list(self.snippets.keys())\n",
    "            elif self.args.negative_sample_method == \"mix\":\n",
    "                candidates = example[\"candidates\"] + random.sample(list(self.snippets.keys()), k=len(example[\"candidates\"]))\n",
    "            elif self.args.negative_sample_method == \"oracle\":\n",
    "                candidates = example[\"candidates\"]\n",
    "            else: \n",
    "                raise ValueError(\"negative_sample_method must be all, mix, or oracle, got %s\" % self.args.negative_sample_method)\n",
    "\n",
    "        candidate_keys = candidates\n",
    "        this_inst[\"candidate_keys\"] = candidate_keys\n",
    "        candidates = [self.snippets[cand_key] for cand_key in candidates]\n",
    "\n",
    "        if self.split_type == \"train\":\n",
    "            candidates = self._shrink_label_cands(example[\"knowledge\"], candidates)\n",
    "            # candidates: [examples[\"knowledge\"] + neg_sampled_knowledge]\n",
    "\n",
    "        label_idx = candidates.index(example[\"knowledge\"])\n",
    "            \n",
    "        this_inst[\"label_idx\"] = label_idx\n",
    "        for cand in candidates:\n",
    "            instance, _ = self.build_input_from_segments(\n",
    "                cand,\n",
    "                example[\"history\"]\n",
    "            )\n",
    "            this_inst[\"input_ids\"].append(instance[\"input_ids\"])\n",
    "            this_inst[\"token_type_ids\"].append(instance[\"token_type_ids\"])\n",
    "            this_inst[\"mc_token_ids\"].append(instance[\"mc_token_ids\"])\n",
    "\n",
    "        return this_inst\n",
    "\n",
    "    def build_input_from_segments(self, knowledge, history):\n",
    "        \"\"\" Build a sequence of input from 2 segments: knowledge and history\"\"\"\n",
    "        instance = {}\n",
    "\n",
    "        sequence = [[self.bos]] + history\n",
    "        sequence_with_speaker = [\n",
    "            [self.speaker1 if (len(sequence) - i) % 2 == 0 else self.speaker2] + s\n",
    "            for i, s in enumerate(sequence[1:])\n",
    "        ]\n",
    "        sequence = [sequence[0]] + sequence_with_speaker + [[self.knowledge_tag] + knowledge + [self.eos]]\n",
    "\n",
    "        instance[\"input_ids\"] = list(chain(*sequence))\n",
    "        instance[\"token_type_ids\"] = [0 for s in sequence[:-1] for _ in s] + [1 for _ in sequence[-1]]\n",
    "        instance[\"mc_token_ids\"] = len(instance[\"input_ids\"]) - 1\n",
    "\n",
    "        return instance, sequence\n",
    "    \n",
    "    def _shrink_label_cands(self, label, candidates):\n",
    "        shrunk_label_cands = candidates.copy()\n",
    "        shrunk_label_cands.remove(label)\n",
    "        shrunk_label_cands = random.sample(shrunk_label_cands, k=self.args.n_candidates-1)\n",
    "        shrunk_label_cands.append(label)\n",
    "        random.shuffle(shrunk_label_cands)\n",
    "\n",
    "        return shrunk_label_cands\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        input_ids = [ids for ins in batch for ids in ins[\"input_ids\"]]\n",
    "        token_type_ids = [ids for ins in batch for ids in ins[\"token_type_ids\"]]\n",
    "        mc_token_ids = [id for ins in batch for id in ins[\"mc_token_ids\"]]\n",
    "        label_idx = [ins[\"label_idx\"] for ins in batch]\n",
    "\n",
    "        data_info = {\n",
    "            \"dialog_ids\": [ins[\"dialog_id\"] for ins in batch],\n",
    "            \"candidate_keys\": [ins[\"candidate_keys\"] for ins in batch]\n",
    "        }\n",
    "\n",
    "        batch_size = len(batch)\n",
    "        n_candidates = len(batch[0][\"input_ids\"])\n",
    "        input_ids = torch.tensor(\n",
    "            pad_ids(input_ids, self.tokenizer.pad_token_id)\n",
    "        ).view(batch_size, n_candidates, -1)\n",
    "        \n",
    "        token_type_ids = torch.tensor(\n",
    "            pad_ids(token_type_ids, self.tokenizer.pad_token_type_id)\n",
    "        ).view(batch_size, n_candidates, -1)\n",
    "\n",
    "        lm_labels = torch.full_like(input_ids, -100)\n",
    "        mc_token_ids = torch.tensor(mc_token_ids).view(batch_size, n_candidates)\n",
    "        label_idx = torch.tensor(label_idx)\n",
    "\n",
    "        return input_ids, token_type_ids, mc_token_ids, lm_labels, label_idx, data_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Namespace:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "        \n",
    "args = Namespace(\n",
    "        dataroot = 'data',\n",
    "        task = \"selection\",\n",
    "        history_max_tokens = 128,\n",
    "        history_max_utterances = 10000,\n",
    "        knowledge_file = \"knowledge.json\",\n",
    "        knowledge_max_tokens = 128,\n",
    "        n_candidates = 3,\n",
    "        negative_sample_method = \"mix\",\n",
    "        eval_all_snippets = None, \n",
    "        local_rank = -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90a6deb055b148d2ae5d630e3e110700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=17201.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bec464827a7440bbcf44f88620b365e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=17201.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = KnowledgeSelectionDataset(args, tokenizer, split_type=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dialog_id': 1,\n",
       " 'input_ids': [[100,\n",
       "   100,\n",
       "   2833,\n",
       "   1999,\n",
       "   2568,\n",
       "   1029,\n",
       "   100,\n",
       "   1045,\n",
       "   1005,\n",
       "   1040,\n",
       "   2066,\n",
       "   2000,\n",
       "   2031,\n",
       "   2070,\n",
       "   2822,\n",
       "   2833,\n",
       "   1012,\n",
       "   100,\n",
       "   2008,\n",
       "   25142,\n",
       "   2091,\n",
       "   1996,\n",
       "   4825,\n",
       "   9804,\n",
       "   2000,\n",
       "   2184,\n",
       "   1012,\n",
       "   2003,\n",
       "   2045,\n",
       "   1037,\n",
       "   3976,\n",
       "   2846,\n",
       "   2017,\n",
       "   2052,\n",
       "   2066,\n",
       "   2000,\n",
       "   2994,\n",
       "   1999,\n",
       "   1029,\n",
       "   100,\n",
       "   1045,\n",
       "   2572,\n",
       "   2559,\n",
       "   2005,\n",
       "   1037,\n",
       "   17844,\n",
       "   21125,\n",
       "   2173,\n",
       "   2000,\n",
       "   4521,\n",
       "   1010,\n",
       "   1045,\n",
       "   2572,\n",
       "   2036,\n",
       "   2559,\n",
       "   2000,\n",
       "   2338,\n",
       "   1037,\n",
       "   2282,\n",
       "   1999,\n",
       "   1996,\n",
       "   2958,\n",
       "   4113,\n",
       "   2160,\n",
       "   3309,\n",
       "   1012,\n",
       "   100,\n",
       "   2029,\n",
       "   5246,\n",
       "   2097,\n",
       "   2017,\n",
       "   2022,\n",
       "   6595,\n",
       "   2012,\n",
       "   1996,\n",
       "   2958,\n",
       "   4113,\n",
       "   2282,\n",
       "   2160,\n",
       "   1029,\n",
       "   100,\n",
       "   2077,\n",
       "   1045,\n",
       "   10797,\n",
       "   1045,\n",
       "   2031,\n",
       "   1037,\n",
       "   2261,\n",
       "   3980,\n",
       "   1012,\n",
       "   2054,\n",
       "   2181,\n",
       "   2003,\n",
       "   1996,\n",
       "   3309,\n",
       "   2284,\n",
       "   1999,\n",
       "   1029,\n",
       "   100,\n",
       "   1996,\n",
       "   3309,\n",
       "   2003,\n",
       "   1999,\n",
       "   1996,\n",
       "   2148,\n",
       "   2181,\n",
       "   1012,\n",
       "   100,\n",
       "   2079,\n",
       "   2027,\n",
       "   2031,\n",
       "   2393,\n",
       "   2005,\n",
       "   9776,\n",
       "   5581,\n",
       "   1029,\n",
       "   100,\n",
       "   2748,\n",
       "   1012,\n",
       "   2023,\n",
       "   3200,\n",
       "   2038,\n",
       "   7801,\n",
       "   5581,\n",
       "   1012,\n",
       "   2151,\n",
       "   2060,\n",
       "   3160,\n",
       "   1029,\n",
       "   100,\n",
       "   2003,\n",
       "   1037,\n",
       "   9425,\n",
       "   4003,\n",
       "   11701,\n",
       "   2005,\n",
       "   2023,\n",
       "   21725,\n",
       "   1029,\n",
       "   100,\n",
       "   12849,\n",
       "   10606,\n",
       "   16506,\n",
       "   1026,\n",
       "   3716,\n",
       "   1035,\n",
       "   19802,\n",
       "   1028,\n",
       "   2515,\n",
       "   12849,\n",
       "   10606,\n",
       "   16506,\n",
       "   2031,\n",
       "   23566,\n",
       "   7047,\n",
       "   2006,\n",
       "   1996,\n",
       "   12183,\n",
       "   1029,\n",
       "   1026,\n",
       "   3716,\n",
       "   1035,\n",
       "   19802,\n",
       "   1028,\n",
       "   2748,\n",
       "   1010,\n",
       "   1996,\n",
       "   4825,\n",
       "   2003,\n",
       "   23566,\n",
       "   5379,\n",
       "   1012,\n",
       "   100],\n",
       "  [100,\n",
       "   100,\n",
       "   2833,\n",
       "   1999,\n",
       "   2568,\n",
       "   1029,\n",
       "   100,\n",
       "   1045,\n",
       "   1005,\n",
       "   1040,\n",
       "   2066,\n",
       "   2000,\n",
       "   2031,\n",
       "   2070,\n",
       "   2822,\n",
       "   2833,\n",
       "   1012,\n",
       "   100,\n",
       "   2008,\n",
       "   25142,\n",
       "   2091,\n",
       "   1996,\n",
       "   4825,\n",
       "   9804,\n",
       "   2000,\n",
       "   2184,\n",
       "   1012,\n",
       "   2003,\n",
       "   2045,\n",
       "   1037,\n",
       "   3976,\n",
       "   2846,\n",
       "   2017,\n",
       "   2052,\n",
       "   2066,\n",
       "   2000,\n",
       "   2994,\n",
       "   1999,\n",
       "   1029,\n",
       "   100,\n",
       "   1045,\n",
       "   2572,\n",
       "   2559,\n",
       "   2005,\n",
       "   1037,\n",
       "   17844,\n",
       "   21125,\n",
       "   2173,\n",
       "   2000,\n",
       "   4521,\n",
       "   1010,\n",
       "   1045,\n",
       "   2572,\n",
       "   2036,\n",
       "   2559,\n",
       "   2000,\n",
       "   2338,\n",
       "   1037,\n",
       "   2282,\n",
       "   1999,\n",
       "   1996,\n",
       "   2958,\n",
       "   4113,\n",
       "   2160,\n",
       "   3309,\n",
       "   1012,\n",
       "   100,\n",
       "   2029,\n",
       "   5246,\n",
       "   2097,\n",
       "   2017,\n",
       "   2022,\n",
       "   6595,\n",
       "   2012,\n",
       "   1996,\n",
       "   2958,\n",
       "   4113,\n",
       "   2282,\n",
       "   2160,\n",
       "   1029,\n",
       "   100,\n",
       "   2077,\n",
       "   1045,\n",
       "   10797,\n",
       "   1045,\n",
       "   2031,\n",
       "   1037,\n",
       "   2261,\n",
       "   3980,\n",
       "   1012,\n",
       "   2054,\n",
       "   2181,\n",
       "   2003,\n",
       "   1996,\n",
       "   3309,\n",
       "   2284,\n",
       "   1999,\n",
       "   1029,\n",
       "   100,\n",
       "   1996,\n",
       "   3309,\n",
       "   2003,\n",
       "   1999,\n",
       "   1996,\n",
       "   2148,\n",
       "   2181,\n",
       "   1012,\n",
       "   100,\n",
       "   2079,\n",
       "   2027,\n",
       "   2031,\n",
       "   2393,\n",
       "   2005,\n",
       "   9776,\n",
       "   5581,\n",
       "   1029,\n",
       "   100,\n",
       "   2748,\n",
       "   1012,\n",
       "   2023,\n",
       "   3200,\n",
       "   2038,\n",
       "   7801,\n",
       "   5581,\n",
       "   1012,\n",
       "   2151,\n",
       "   2060,\n",
       "   3160,\n",
       "   1029,\n",
       "   100,\n",
       "   2003,\n",
       "   1037,\n",
       "   9425,\n",
       "   4003,\n",
       "   11701,\n",
       "   2005,\n",
       "   2023,\n",
       "   21725,\n",
       "   1029,\n",
       "   100,\n",
       "   2958,\n",
       "   4113,\n",
       "   2160,\n",
       "   1026,\n",
       "   3716,\n",
       "   1035,\n",
       "   19802,\n",
       "   1028,\n",
       "   2054,\n",
       "   2003,\n",
       "   1996,\n",
       "   3465,\n",
       "   1997,\n",
       "   15536,\n",
       "   8873,\n",
       "   2012,\n",
       "   2115,\n",
       "   3295,\n",
       "   1029,\n",
       "   1026,\n",
       "   3716,\n",
       "   1035,\n",
       "   19802,\n",
       "   1028,\n",
       "   2489,\n",
       "   15536,\n",
       "   8873,\n",
       "   2003,\n",
       "   2800,\n",
       "   2012,\n",
       "   1996,\n",
       "   2958,\n",
       "   4113,\n",
       "   2160,\n",
       "   1012,\n",
       "   100],\n",
       "  [100,\n",
       "   100,\n",
       "   2833,\n",
       "   1999,\n",
       "   2568,\n",
       "   1029,\n",
       "   100,\n",
       "   1045,\n",
       "   1005,\n",
       "   1040,\n",
       "   2066,\n",
       "   2000,\n",
       "   2031,\n",
       "   2070,\n",
       "   2822,\n",
       "   2833,\n",
       "   1012,\n",
       "   100,\n",
       "   2008,\n",
       "   25142,\n",
       "   2091,\n",
       "   1996,\n",
       "   4825,\n",
       "   9804,\n",
       "   2000,\n",
       "   2184,\n",
       "   1012,\n",
       "   2003,\n",
       "   2045,\n",
       "   1037,\n",
       "   3976,\n",
       "   2846,\n",
       "   2017,\n",
       "   2052,\n",
       "   2066,\n",
       "   2000,\n",
       "   2994,\n",
       "   1999,\n",
       "   1029,\n",
       "   100,\n",
       "   1045,\n",
       "   2572,\n",
       "   2559,\n",
       "   2005,\n",
       "   1037,\n",
       "   17844,\n",
       "   21125,\n",
       "   2173,\n",
       "   2000,\n",
       "   4521,\n",
       "   1010,\n",
       "   1045,\n",
       "   2572,\n",
       "   2036,\n",
       "   2559,\n",
       "   2000,\n",
       "   2338,\n",
       "   1037,\n",
       "   2282,\n",
       "   1999,\n",
       "   1996,\n",
       "   2958,\n",
       "   4113,\n",
       "   2160,\n",
       "   3309,\n",
       "   1012,\n",
       "   100,\n",
       "   2029,\n",
       "   5246,\n",
       "   2097,\n",
       "   2017,\n",
       "   2022,\n",
       "   6595,\n",
       "   2012,\n",
       "   1996,\n",
       "   2958,\n",
       "   4113,\n",
       "   2282,\n",
       "   2160,\n",
       "   1029,\n",
       "   100,\n",
       "   2077,\n",
       "   1045,\n",
       "   10797,\n",
       "   1045,\n",
       "   2031,\n",
       "   1037,\n",
       "   2261,\n",
       "   3980,\n",
       "   1012,\n",
       "   2054,\n",
       "   2181,\n",
       "   2003,\n",
       "   1996,\n",
       "   3309,\n",
       "   2284,\n",
       "   1999,\n",
       "   1029,\n",
       "   100,\n",
       "   1996,\n",
       "   3309,\n",
       "   2003,\n",
       "   1999,\n",
       "   1996,\n",
       "   2148,\n",
       "   2181,\n",
       "   1012,\n",
       "   100,\n",
       "   2079,\n",
       "   2027,\n",
       "   2031,\n",
       "   2393,\n",
       "   2005,\n",
       "   9776,\n",
       "   5581,\n",
       "   1029,\n",
       "   100,\n",
       "   2748,\n",
       "   1012,\n",
       "   2023,\n",
       "   3200,\n",
       "   2038,\n",
       "   7801,\n",
       "   5581,\n",
       "   1012,\n",
       "   2151,\n",
       "   2060,\n",
       "   3160,\n",
       "   1029,\n",
       "   100,\n",
       "   2003,\n",
       "   1037,\n",
       "   9425,\n",
       "   4003,\n",
       "   11701,\n",
       "   2005,\n",
       "   2023,\n",
       "   21725,\n",
       "   1029,\n",
       "   100,\n",
       "   2958,\n",
       "   4113,\n",
       "   2160,\n",
       "   1026,\n",
       "   3716,\n",
       "   1035,\n",
       "   19802,\n",
       "   1028,\n",
       "   2054,\n",
       "   7909,\n",
       "   7047,\n",
       "   2024,\n",
       "   3970,\n",
       "   2012,\n",
       "   2958,\n",
       "   4113,\n",
       "   2160,\n",
       "   1029,\n",
       "   1026,\n",
       "   3716,\n",
       "   1035,\n",
       "   19802,\n",
       "   1028,\n",
       "   9425,\n",
       "   1998,\n",
       "   3040,\n",
       "   11522,\n",
       "   2024,\n",
       "   3970,\n",
       "   2012,\n",
       "   2958,\n",
       "   4113,\n",
       "   2160,\n",
       "   100]],\n",
       " 'token_type_ids': [[0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1]],\n",
       " 'mc_token_ids': [172, 175, 173],\n",
       " 'candidate_keys': ['hotel__11__0',\n",
       "  'hotel__11__1',\n",
       "  'hotel__11__2',\n",
       "  'hotel__11__3',\n",
       "  'hotel__11__4',\n",
       "  'hotel__11__5',\n",
       "  'hotel__11__6',\n",
       "  'hotel__11__7',\n",
       "  'hotel__11__8',\n",
       "  'hotel__11__9',\n",
       "  'hotel__11__10',\n",
       "  'hotel__11__11',\n",
       "  'hotel__11__12',\n",
       "  'hotel__11__13',\n",
       "  'hotel__11__14',\n",
       "  'hotel__11__15',\n",
       "  'hotel__11__16',\n",
       "  'hotel__11__17',\n",
       "  'hotel__11__18',\n",
       "  'hotel__11__19',\n",
       "  'hotel__11__20',\n",
       "  'hotel__11__21',\n",
       "  'hotel__11__22',\n",
       "  'hotel__11__23',\n",
       "  'hotel__11__24',\n",
       "  'hotel__11__25',\n",
       "  'hotel__11__26',\n",
       "  'hotel__11__27',\n",
       "  'hotel__11__28',\n",
       "  'hotel__11__29',\n",
       "  'hotel__11__30',\n",
       "  'hotel__11__31',\n",
       "  'hotel__11__32',\n",
       "  'hotel__11__33',\n",
       "  'hotel__11__34',\n",
       "  'hotel__11__35',\n",
       "  'hotel__11__36',\n",
       "  'hotel__11__37',\n",
       "  'hotel__27__28',\n",
       "  'hotel__24__33',\n",
       "  'hotel__17__15',\n",
       "  'restaurant__19189__9',\n",
       "  'restaurant__19217__4',\n",
       "  'restaurant__19256__4',\n",
       "  'hotel__25__20',\n",
       "  'hotel__19__2',\n",
       "  'hotel__26__8',\n",
       "  'restaurant__19180__0',\n",
       "  'restaurant__19178__6',\n",
       "  'restaurant__19211__9',\n",
       "  'hotel__8__15',\n",
       "  'hotel__9__33',\n",
       "  'restaurant__19255__3',\n",
       "  'restaurant__19260__2',\n",
       "  'restaurant__19230__14',\n",
       "  'hotel__21__20',\n",
       "  'restaurant__19273__14',\n",
       "  'hotel__4__8',\n",
       "  'restaurant__19176__13',\n",
       "  'hotel__24__17',\n",
       "  'restaurant__19212__3',\n",
       "  'restaurant__19214__5',\n",
       "  'restaurant__12566__3',\n",
       "  'restaurant__19221__12',\n",
       "  'restaurant__19246__3',\n",
       "  'restaurant__19217__14',\n",
       "  'restaurant__19171__11',\n",
       "  'restaurant__19252__9',\n",
       "  'restaurant__19189__3',\n",
       "  'hotel__13__24',\n",
       "  'restaurant__31390__7',\n",
       "  'restaurant__19195__11',\n",
       "  'restaurant__19238__12',\n",
       "  'restaurant__19227__6',\n",
       "  'hotel__0__18',\n",
       "  'restaurant__19188__13'],\n",
       " 'label_idx': 2}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[  100,   100,  2833,  1999,  2568,  1029,   100,  1045,  1005,  1040,\n",
       "            2066,  2000,  2031,  2070,  2822,  2833,  1012,   100,  2008, 25142,\n",
       "            2091,  1996,  4825,  9804,  2000,  2184,  1012,  2003,  2045,  1037,\n",
       "            3976,  2846,  2017,  2052,  2066,  2000,  2994,  1999,  1029,   100,\n",
       "            1045,  2572,  2559,  2005,  1037, 17844, 21125,  2173,  2000,  4521,\n",
       "            1010,  1045,  2572,  2036,  2559,  2000,  2338,  1037,  2282,  1999,\n",
       "            1996,  2958,  4113,  2160,  3309,  1012,   100,  2029,  5246,  2097,\n",
       "            2017,  2022,  6595,  2012,  1996,  2958,  4113,  2282,  2160,  1029,\n",
       "             100,  2077,  1045, 10797,  1045,  2031,  1037,  2261,  3980,  1012,\n",
       "            2054,  2181,  2003,  1996,  3309,  2284,  1999,  1029,   100,  1996,\n",
       "            3309,  2003,  1999,  1996,  2148,  2181,  1012,   100,  2079,  2027,\n",
       "            2031,  2393,  2005,  9776,  5581,  1029,   100,  2748,  1012,  2023,\n",
       "            3200,  2038,  7801,  5581,  1012,  2151,  2060,  3160,  1029,   100,\n",
       "            2003,  1037,  9425,  4003, 11701,  2005,  2023, 21725,  1029,   100,\n",
       "            2958,  4113,  2160,  1026,  3716,  1035, 19802,  1028,  2024,  2045,\n",
       "            2151, 10516,  2415,  2030,  9726,  1029,  1026,  3716,  1035, 19802,\n",
       "            1028,  2958,  4113,  2160,  2515,  2025,  2031,  1037, 10516,  2415,\n",
       "            2030,  9726,  2006, 28032,  2063,  1012,   100],\n",
       "          [  100,   100,  2833,  1999,  2568,  1029,   100,  1045,  1005,  1040,\n",
       "            2066,  2000,  2031,  2070,  2822,  2833,  1012,   100,  2008, 25142,\n",
       "            2091,  1996,  4825,  9804,  2000,  2184,  1012,  2003,  2045,  1037,\n",
       "            3976,  2846,  2017,  2052,  2066,  2000,  2994,  1999,  1029,   100,\n",
       "            1045,  2572,  2559,  2005,  1037, 17844, 21125,  2173,  2000,  4521,\n",
       "            1010,  1045,  2572,  2036,  2559,  2000,  2338,  1037,  2282,  1999,\n",
       "            1996,  2958,  4113,  2160,  3309,  1012,   100,  2029,  5246,  2097,\n",
       "            2017,  2022,  6595,  2012,  1996,  2958,  4113,  2282,  2160,  1029,\n",
       "             100,  2077,  1045, 10797,  1045,  2031,  1037,  2261,  3980,  1012,\n",
       "            2054,  2181,  2003,  1996,  3309,  2284,  1999,  1029,   100,  1996,\n",
       "            3309,  2003,  1999,  1996,  2148,  2181,  1012,   100,  2079,  2027,\n",
       "            2031,  2393,  2005,  9776,  5581,  1029,   100,  2748,  1012,  2023,\n",
       "            3200,  2038,  7801,  5581,  1012,  2151,  2060,  3160,  1029,   100,\n",
       "            2003,  1037,  9425,  4003, 11701,  2005,  2023, 21725,  1029,   100,\n",
       "            2958,  4113,  2160,  1026,  3716,  1035, 19802,  1028,  2054,  7909,\n",
       "            7047,  2024,  3970,  2012,  2958,  4113,  2160,  1029,  1026,  3716,\n",
       "            1035, 19802,  1028,  9425,  1998,  3040, 11522,  2024,  3970,  2012,\n",
       "            2958,  4113,  2160,   100,     0,     0,     0],\n",
       "          [  100,   100,  2833,  1999,  2568,  1029,   100,  1045,  1005,  1040,\n",
       "            2066,  2000,  2031,  2070,  2822,  2833,  1012,   100,  2008, 25142,\n",
       "            2091,  1996,  4825,  9804,  2000,  2184,  1012,  2003,  2045,  1037,\n",
       "            3976,  2846,  2017,  2052,  2066,  2000,  2994,  1999,  1029,   100,\n",
       "            1045,  2572,  2559,  2005,  1037, 17844, 21125,  2173,  2000,  4521,\n",
       "            1010,  1045,  2572,  2036,  2559,  2000,  2338,  1037,  2282,  1999,\n",
       "            1996,  2958,  4113,  2160,  3309,  1012,   100,  2029,  5246,  2097,\n",
       "            2017,  2022,  6595,  2012,  1996,  2958,  4113,  2282,  2160,  1029,\n",
       "             100,  2077,  1045, 10797,  1045,  2031,  1037,  2261,  3980,  1012,\n",
       "            2054,  2181,  2003,  1996,  3309,  2284,  1999,  1029,   100,  1996,\n",
       "            3309,  2003,  1999,  1996,  2148,  2181,  1012,   100,  2079,  2027,\n",
       "            2031,  2393,  2005,  9776,  5581,  1029,   100,  2748,  1012,  2023,\n",
       "            3200,  2038,  7801,  5581,  1012,  2151,  2060,  3160,  1029,   100,\n",
       "            2003,  1037,  9425,  4003, 11701,  2005,  2023, 21725,  1029,   100,\n",
       "            2474, 11937, 15782,  1026,  3716,  1035, 19802,  1028,  2515,  1996,\n",
       "            2474, 11937, 15782,  2031, 23566,  5379,  7047,  1029,  1026,  3716,\n",
       "            1035, 19802,  1028,  2474, 11937, 15782,  2515,  2025,  2031, 23566,\n",
       "            5379,  7047,  1012,   100,     0,     0,     0]]]),\n",
       " tensor([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "           0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]]]),\n",
       " tensor([[176, 173, 173]]),\n",
       " tensor([[[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100],\n",
       "          [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100],\n",
       "          [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100]]]),\n",
       " tensor([1]),\n",
       " {'dialog_ids': [1],\n",
       "  'candidate_keys': [['hotel__11__0',\n",
       "    'hotel__11__1',\n",
       "    'hotel__11__2',\n",
       "    'hotel__11__3',\n",
       "    'hotel__11__4',\n",
       "    'hotel__11__5',\n",
       "    'hotel__11__6',\n",
       "    'hotel__11__7',\n",
       "    'hotel__11__8',\n",
       "    'hotel__11__9',\n",
       "    'hotel__11__10',\n",
       "    'hotel__11__11',\n",
       "    'hotel__11__12',\n",
       "    'hotel__11__13',\n",
       "    'hotel__11__14',\n",
       "    'hotel__11__15',\n",
       "    'hotel__11__16',\n",
       "    'hotel__11__17',\n",
       "    'hotel__11__18',\n",
       "    'hotel__11__19',\n",
       "    'hotel__11__20',\n",
       "    'hotel__11__21',\n",
       "    'hotel__11__22',\n",
       "    'hotel__11__23',\n",
       "    'hotel__11__24',\n",
       "    'hotel__11__25',\n",
       "    'hotel__11__26',\n",
       "    'hotel__11__27',\n",
       "    'hotel__11__28',\n",
       "    'hotel__11__29',\n",
       "    'hotel__11__30',\n",
       "    'hotel__11__31',\n",
       "    'hotel__11__32',\n",
       "    'hotel__11__33',\n",
       "    'hotel__11__34',\n",
       "    'hotel__11__35',\n",
       "    'hotel__11__36',\n",
       "    'hotel__11__37',\n",
       "    'restaurant__19235__4',\n",
       "    'hotel__27__0',\n",
       "    'restaurant__19245__13',\n",
       "    'hotel__32__20',\n",
       "    'hotel__12__27',\n",
       "    'restaurant__19213__3',\n",
       "    'restaurant__19237__1',\n",
       "    'hotel__4__35',\n",
       "    'train__*__10',\n",
       "    'restaurant__19211__7',\n",
       "    'restaurant__19274__9',\n",
       "    'restaurant__19214__5',\n",
       "    'restaurant__19227__0',\n",
       "    'restaurant__19196__8',\n",
       "    'restaurant__19239__11',\n",
       "    'restaurant__14731__4',\n",
       "    'restaurant__19269__9',\n",
       "    'restaurant__4607__12',\n",
       "    'restaurant__19242__14',\n",
       "    'restaurant__14731__6',\n",
       "    'restaurant__19176__14',\n",
       "    'restaurant__19218__6',\n",
       "    'hotel__11__14',\n",
       "    'restaurant__19268__12',\n",
       "    'hotel__19__22',\n",
       "    'restaurant__12566__14',\n",
       "    'hotel__1__14',\n",
       "    'restaurant__19176__11',\n",
       "    'hotel__24__7',\n",
       "    'hotel__25__31',\n",
       "    'hotel__21__5',\n",
       "    'hotel__25__18',\n",
       "    'restaurant__19257__12',\n",
       "    'hotel__21__29',\n",
       "    'hotel__10__1',\n",
       "    'hotel__10__4',\n",
       "    'restaurant__19231__3',\n",
       "    'restaurant__19236__6']]})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.collate_fn([train_dataset[1]])\n",
    "# input_ids, token_type_ids, mc_token_ids, lm_labels, label_idx, data_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['history', 'knowledge', 'candidates', 'response', 'response_text', 'label', 'knowledge_seeking', 'dialog_id'])\n",
      "\n",
      "history\n",
      "[[2833, 1999, 2568, 1029], [1045, 1005, 1040, 2066, 2000, 2031, 2070, 2822, 2833, 1012], [2008, 25142, 2091, 1996, 4825, 9804, 2000, 2184, 1012, 2003, 2045, 1037, 3976, 2846, 2017, 2052, 2066, 2000, 2994, 1999, 1029], [1045, 2572, 2559, 2005, 1037, 17844, 21125, 2173, 2000, 4521, 1010, 1045, 2572, 2036, 2559, 2000, 2338, 1037, 2282, 1999, 1996, 2958, 4113, 2160, 3309, 1012], [2029, 5246, 2097, 2017, 2022, 6595, 2012, 1996, 2958, 4113, 2282, 2160, 1029], [2077, 1045, 10797, 1045, 2031, 1037, 2261, 3980, 1012, 2054, 2181, 2003, 1996, 3309, 2284, 1999, 1029], [1996, 3309, 2003, 1999, 1996, 2148, 2181, 1012], [2079, 2027, 2031, 2393, 2005, 9776, 5581, 1029], [2748, 1012, 2023, 3200, 2038, 7801, 5581, 1012, 2151, 2060, 3160, 1029], [2003, 1037, 9425, 4003, 11701, 2005, 2023, 21725, 1029]]\n",
      "\n",
      "knowledge\n",
      "[2958, 4113, 2160, 1026, 3716, 1035, 19802, 1028, 2054, 7909, 7047, 2024, 3970, 2012, 2958, 4113, 2160, 1029, 1026, 3716, 1035, 19802, 1028, 9425, 1998, 3040, 11522, 2024, 3970, 2012, 2958, 4113, 2160]\n",
      "\n",
      "candidates\n",
      "['hotel__11__0', 'hotel__11__1', 'hotel__11__2', 'hotel__11__3', 'hotel__11__4', 'hotel__11__5', 'hotel__11__6', 'hotel__11__7', 'hotel__11__8', 'hotel__11__9', 'hotel__11__10', 'hotel__11__11', 'hotel__11__12', 'hotel__11__13', 'hotel__11__14', 'hotel__11__15', 'hotel__11__16', 'hotel__11__17', 'hotel__11__18', 'hotel__11__19', 'hotel__11__20', 'hotel__11__21', 'hotel__11__22', 'hotel__11__23', 'hotel__11__24', 'hotel__11__25', 'hotel__11__26', 'hotel__11__27', 'hotel__11__28', 'hotel__11__29', 'hotel__11__30', 'hotel__11__31', 'hotel__11__32', 'hotel__11__33', 'hotel__11__34', 'hotel__11__35', 'hotel__11__36', 'hotel__11__37']\n",
      "\n",
      "response\n",
      "[2748, 1010, 1996, 2958, 4113, 2160, 13385, 9425, 1998, 3040, 11522, 2004, 1037, 2433, 1997, 7909, 1012, 2079, 2017, 2031, 2151, 2062, 3980, 1029]\n",
      "\n",
      "response_text\n",
      "Yes, The Bridge Guest House accepts Visa and Mastercard as a form of payment. Do you have any more questions?\n",
      "\n",
      "label\n",
      "{'target': True, 'knowledge': [{'domain': 'hotel', 'entity_id': 11, 'doc_id': 13}], 'response': 'Yes, The Bridge Guest House accepts Visa and Mastercard as a form of payment. Do you have any more questions?', 'response_tokenized': [2748, 1010, 1996, 2958, 4113, 2160, 13385, 9425, 1998, 3040, 11522, 2004, 1037, 2433, 1997, 7909, 1012, 2079, 2017, 2031, 2151, 2062, 3980, 1029]}\n",
      "\n",
      "knowledge_seeking\n",
      "True\n",
      "\n",
      "dialog_id\n",
      "1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.examples[1].keys())\n",
    "print()\n",
    "for key in train_dataset.examples[1].keys():\n",
    "    print(key)\n",
    "    print(train_dataset.examples[1][key])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bridge guest house < knowledge _ sep > are pets allowed here ? < knowledge _ sep > no , pets are not allowed at this property .'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(tokenizer.convert_ids_to_tokens(train_dataset.snippets[\"hotel__11__0\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track 2 : Response generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseGenerationDataset(BaseDataset):\n",
    "    def __init__(self, args, tokenizer, split_type, labels=True, labels_file=None):\n",
    "        super(ResponseGenerationDataset, self).__init__(args, tokenizer, split_type, labels, labels_file)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        example = self.examples[index]\n",
    "        instance, _ = self.build_input_from_segments(\n",
    "            example[\"knowledge\"],\n",
    "            example[\"history\"],\n",
    "            example[\"response\"]\n",
    "        )\n",
    "        return instance\n",
    "\n",
    "    def build_input_from_segments(self, knowledge, history, response, with_eos=True):\n",
    "        \"\"\" Build a sequence of input from 3 segments: knowledge, history and last reply \"\"\"\n",
    "        instance = {}\n",
    "\n",
    "        sequence = [[self.bos] + knowledge] + history + [response + ([self.eos] if with_eos else [])]\n",
    "        sequence_with_speaker = [\n",
    "            [self.speaker1 if (len(sequence) - i) % 2 == 0 else self.speaker2] + s\n",
    "            for i, s in enumerate(sequence[1:])\n",
    "        ]\n",
    "        sequence = [sequence[0]] + sequence_with_speaker\n",
    "        instance[\"input_ids\"] = list(chain(*sequence))\n",
    "        instance[\"token_type_ids\"] = [self.speaker2 if i % 2 else self.speaker1\n",
    "                                      for i, s in enumerate(sequence) for _ in s]\n",
    "        instance[\"mc_token_ids\"] = len(instance[\"input_ids\"]) - 1\n",
    "        instance[\"lm_labels\"] = ([-100] * sum(len(s) for s in sequence[:-1])) + [-100] + sequence[-1][1:]\n",
    "\n",
    "        return instance, sequence\n",
    "    \n",
    "    def collate_fn(self, batch):\n",
    "        input_ids = [ins[\"input_ids\"] for ins in batch]\n",
    "        token_type_ids = [ins[\"token_type_ids\"] for ins in batch]\n",
    "        lm_labels = [ins[\"lm_labels\"] for ins in batch]\n",
    "\n",
    "        input_ids = torch.tensor(pad_ids(input_ids, self.tokenizer.pad_id))\n",
    "        token_type_ids = torch.tensor(pad_ids(token_type_ids, self.tokenizer.pad_token_type_id))\n",
    "        lm_labels = torch.tensor(pad_ids(lm_labels, -100))\n",
    "\n",
    "        return input_ids, token_type_ids, lm_labels\n",
    "\n",
    "\n",
    "class ResponseGenerationEvalDataset(BaseDataset):\n",
    "    def __init__(self, args, tokenizer, split_type, labels=True, labels_file=None):\n",
    "        super(ResponseGenerationEvalDataset, self).__init__(args, tokenizer, split_type, labels, labels_file)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        example = self.examples[index]\n",
    "        return example\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.task = \"generation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c884f914af984d338451a6decc2f9cb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=17201.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "122f9d58a1f1404b8d6249ff5cba5635",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=17201.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generation_dataset = ResponseGenerationDataset(args, tokenizer, split_type=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'mc_token_ids', 'lm_labels'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_dataset[1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "febc0e4583d04f5c8bd90679a5cf70f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=176.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc93c7c4bd34c01ab21cda6e99ba42e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=176.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generation_eval_dataset = ResponseGenerationEvalDataset(args, tokenizer, split_type=\"val\",\n",
    "                                                      labels_file=args.labels_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['history', 'knowledge', 'candidates', 'response', 'response_text', 'label', 'knowledge_seeking', 'dialog_id'])\n",
      "\n",
      "history [[1045, 2342, 1037, 3345, 2000, 20779, 1010, 3531, 1012], [2054, 2154, 2097, 2017, 2022, 7118, 1029], [1045, 2097, 2022, 2975, 4465, 2044, 2539, 1024, 2382, 1012], [2064, 1045, 3198, 2073, 2017, 2024, 2975, 2013, 1029], [1045, 2097, 2022, 2975, 2013, 4729, 2006, 4465, 2044, 2539, 1024, 2382, 1012], [1045, 2031, 3345, 19817, 19481, 22932, 2975, 2012, 2539, 1024, 2753, 1998, 7194, 2011, 2322, 1024, 5718, 1012, 2052, 2023, 2147, 2005, 2017, 1029], [2073, 2064, 1045, 2380, 2026, 2482, 2012, 1996, 2276, 1029]]\n",
      "\n",
      "knowledge [2017, 2089, 2380, 2012, 1996, 2276, 1010, 2045, 2089, 2022, 1037, 7408, 1010, 2017, 2323, 4638, 2007, 2115, 2276, 1012]\n",
      "\n",
      "candidates ['train__*__1', 'train__*__2', 'train__*__3', 'train__*__4', 'train__*__5', 'train__*__6', 'train__*__7', 'train__*__8', 'train__*__9', 'train__*__10', 'train__*__11', 'train__*__12', 'train__*__13', 'train__*__14', 'train__*__15', 'train__*__16', 'train__*__17', 'train__*__18', 'train__*__19', 'train__*__20', 'train__*__21', 'train__*__22', 'train__*__23', 'train__*__24', 'train__*__25', 'train__*__26']\n",
      "\n",
      "response [2045, 2003, 1037, 2843, 2000, 2380, 1999, 1010, 2295, 2045, 2089, 2022, 1037, 7408, 1012, 3531, 4638, 2012, 1996, 2276, 1012, 2054, 2842, 2064, 1045, 2425, 2017, 1029]\n",
      "\n",
      "response_text There is a lot to park in, though there may be a fee. Please check at the station. What else can I tell you?\n",
      "\n",
      "label {'target': True, 'knowledge': [{'domain': 'train', 'entity_id': '*', 'doc_id': 21}], 'response': 'There is a lot to park in, though there may be a fee. Please check at the station. What else can I tell you?', 'response_tokenized': [2045, 2003, 1037, 2843, 2000, 2380, 1999, 1010, 2295, 2045, 2089, 2022, 1037, 7408, 1012, 3531, 4638, 2012, 1996, 2276, 1012, 2054, 2842, 2064, 1045, 2425, 2017, 1029]}\n",
      "\n",
      "knowledge_seeking True\n",
      "\n",
      "dialog_id 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(generation_eval_dataset[1].keys())\n",
    "print()\n",
    "for key in generation_eval_dataset[1]:\n",
    "    print(key, generation_eval_dataset[1][key])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
