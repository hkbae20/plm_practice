{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "from itertools import chain\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from utils.data import pad_ids, truncate_sequences\n",
    "from utils.dataset_walker import DatasetWalker\n",
    "from utils.knowledge_reader import KnowledgeReader\n",
    "\n",
    "from dataset import BaseDataset, SPECIAL_TOKENS\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    AutoConfig,\n",
    "    AutoTokenizer,\n",
    "    GPT2DoubleHeadsModel,\n",
    "    GPT2LMHeadModel,\n",
    "    PreTrainedModel,\n",
    "    PreTrainedTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track 1: Knowledge Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnowledgeSelectionDataset(BaseDataset):\n",
    "    def __init__(self, args, tokenizer, split_type, labels=True, labels_file=None):\n",
    "        super(KnowledgeSelectionDataset, self).__init__(args, tokenizer, split_type, labels, labels_file)\n",
    "        if self.args.negative_sample_method not in [\"all\", \"mix\", \"oracle\"]:\n",
    "            raise ValueError(\"negative_sample_method must be all, mix, or oracle, got %s\" % self.args.negative_sample_method)\n",
    "\n",
    "    def _knowledge_to_string(self, doc, name=\"\"):\n",
    "        join_str = \" %s \" % self.knowledge_sep_token\n",
    "        return join_str.join([name, doc[\"title\"], doc[\"body\"]])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        example = self.examples[index]\n",
    "\n",
    "        this_inst = {\n",
    "            \"dialog_id\": example[\"dialog_id\"],\n",
    "            \"input_ids\": [],\n",
    "            \"token_type_ids\": [],\n",
    "            \"mc_token_ids\": []\n",
    "        }\n",
    "\n",
    "        if self.split_type != \"train\":\n",
    "            # if eval_all_snippets is set, we use all snippets as candidates\n",
    "            if self.args.eval_all_snippets:\n",
    "                candidates = list(self.snippets.keys())\n",
    "            else:\n",
    "                candidates = example[\"candidates\"]\n",
    "        else:\n",
    "            if self.args.negative_sample_method == \"all\":\n",
    "                candidates = list(self.snippets.keys())\n",
    "            elif self.args.negative_sample_method == \"mix\":\n",
    "                candidates = example[\"candidates\"] + random.sample(list(self.snippets.keys()), k=len(example[\"candidates\"]))\n",
    "            elif self.args.negative_sample_method == \"oracle\":\n",
    "                candidates = example[\"candidates\"]\n",
    "            else: \n",
    "                raise ValueError(\"negative_sample_method must be all, mix, or oracle, got %s\" % self.args.negative_sample_method)\n",
    "\n",
    "        candidate_keys = candidates\n",
    "        this_inst[\"candidate_keys\"] = candidate_keys\n",
    "        candidates = [self.snippets[cand_key] for cand_key in candidates]\n",
    "\n",
    "        if self.split_type == \"train\":\n",
    "            candidates = self._shrink_label_cands(example[\"knowledge\"], candidates)\n",
    "            # candidates: [examples[\"knowledge\"] + neg_sampled_knowledge]\n",
    "\n",
    "        label_idx = candidates.index(example[\"knowledge\"])\n",
    "            \n",
    "        this_inst[\"label_idx\"] = label_idx\n",
    "        for cand in candidates:\n",
    "            instance, _ = self.build_input_from_segments(\n",
    "                cand,\n",
    "                example[\"history\"]\n",
    "            )\n",
    "            this_inst[\"input_ids\"].append(instance[\"input_ids\"])\n",
    "            this_inst[\"token_type_ids\"].append(instance[\"token_type_ids\"])\n",
    "            this_inst[\"mc_token_ids\"].append(instance[\"mc_token_ids\"])\n",
    "\n",
    "        return this_inst\n",
    "\n",
    "    def build_input_from_segments(self, knowledge, history):\n",
    "        \"\"\" Build a sequence of input from 2 segments: knowledge and history\"\"\"\n",
    "        instance = {}\n",
    "\n",
    "        sequence = [[self.bos]] + history\n",
    "        sequence_with_speaker = [\n",
    "            [self.speaker1 if (len(sequence) - i) % 2 == 0 else self.speaker2] + s\n",
    "            for i, s in enumerate(sequence[1:])\n",
    "        ]\n",
    "        sequence = [sequence[0]] + sequence_with_speaker + [[self.knowledge_tag] + knowledge + [self.eos]]\n",
    "\n",
    "        instance[\"input_ids\"] = list(chain(*sequence))\n",
    "        instance[\"token_type_ids\"] = [0 for s in sequence[:-1] for _ in s] + [1 for _ in sequence[-1]]\n",
    "        instance[\"mc_token_ids\"] = len(instance[\"input_ids\"]) - 1\n",
    "\n",
    "        return instance, sequence\n",
    "    \n",
    "    def _shrink_label_cands(self, label, candidates):\n",
    "        shrunk_label_cands = candidates.copy()\n",
    "        shrunk_label_cands.remove(label)\n",
    "        shrunk_label_cands = random.sample(shrunk_label_cands, k=self.args.n_candidates-1)\n",
    "        shrunk_label_cands.append(label)\n",
    "        random.shuffle(shrunk_label_cands)\n",
    "\n",
    "        return shrunk_label_cands\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        input_ids = [ids for ins in batch for ids in ins[\"input_ids\"]]\n",
    "        token_type_ids = [ids for ins in batch for ids in ins[\"token_type_ids\"]]\n",
    "        mc_token_ids = [id for ins in batch for id in ins[\"mc_token_ids\"]]\n",
    "        label_idx = [ins[\"label_idx\"] for ins in batch]\n",
    "\n",
    "        data_info = {\n",
    "            \"dialog_ids\": [ins[\"dialog_id\"] for ins in batch],\n",
    "            \"candidate_keys\": [ins[\"candidate_keys\"] for ins in batch]\n",
    "        }\n",
    "\n",
    "        batch_size = len(batch)\n",
    "        n_candidates = len(batch[0][\"input_ids\"])\n",
    "        input_ids = torch.tensor(\n",
    "            pad_ids(input_ids, self.pad)\n",
    "        ).view(batch_size, n_candidates, -1)\n",
    "        \n",
    "        token_type_ids = torch.tensor(\n",
    "            pad_ids(token_type_ids, self.pad)\n",
    "        ).view(batch_size, n_candidates, -1)\n",
    "\n",
    "        lm_labels = torch.full_like(input_ids, -100)\n",
    "        mc_token_ids = torch.tensor(mc_token_ids).view(batch_size, n_candidates)\n",
    "        label_idx = torch.tensor(label_idx)\n",
    "\n",
    "        return input_ids, token_type_ids, mc_token_ids, lm_labels, label_idx, data_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Namespace:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "        \n",
    "args = Namespace(\n",
    "        dataroot = 'data',\n",
    "        task = \"selection\",\n",
    "        history_max_tokens = 128,\n",
    "        history_max_utterances = 10000,\n",
    "        knowledge_file = \"knowledge.json\",\n",
    "        knowledge_max_tokens = 128,\n",
    "        n_candidates = 3,\n",
    "        negative_sample_method = \"mix\",\n",
    "        eval_all_snippets = None, \n",
    "        local_rank = -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adc136739db54cba982fe91b44ad2df3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=72518.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f11795f51e24e61bd2bad4579b6be3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=72518.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = KnowledgeSelectionDataset(args, tokenizer, split_type=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dialog_id': 5,\n",
       " 'input_ids': [[100,\n",
       "   100,\n",
       "   2833,\n",
       "   1999,\n",
       "   2568,\n",
       "   1029,\n",
       "   100,\n",
       "   1045,\n",
       "   1005,\n",
       "   1040,\n",
       "   2066,\n",
       "   2000,\n",
       "   2031,\n",
       "   2070,\n",
       "   2822,\n",
       "   2833,\n",
       "   1012,\n",
       "   100,\n",
       "   2008,\n",
       "   25142,\n",
       "   2091,\n",
       "   1996,\n",
       "   4825,\n",
       "   9804,\n",
       "   2000,\n",
       "   2184,\n",
       "   1012,\n",
       "   2003,\n",
       "   2045,\n",
       "   1037,\n",
       "   3976,\n",
       "   2846,\n",
       "   2017,\n",
       "   2052,\n",
       "   2066,\n",
       "   2000,\n",
       "   2994,\n",
       "   1999,\n",
       "   1029,\n",
       "   100,\n",
       "   1045,\n",
       "   2572,\n",
       "   2559,\n",
       "   2005,\n",
       "   1037,\n",
       "   17844,\n",
       "   21125,\n",
       "   2173,\n",
       "   2000,\n",
       "   4521,\n",
       "   1010,\n",
       "   1045,\n",
       "   2572,\n",
       "   2036,\n",
       "   2559,\n",
       "   2000,\n",
       "   2338,\n",
       "   1037,\n",
       "   2282,\n",
       "   1999,\n",
       "   1996,\n",
       "   2958,\n",
       "   4113,\n",
       "   2160,\n",
       "   3309,\n",
       "   1012,\n",
       "   100,\n",
       "   2029,\n",
       "   5246,\n",
       "   2097,\n",
       "   2017,\n",
       "   2022,\n",
       "   6595,\n",
       "   2012,\n",
       "   1996,\n",
       "   2958,\n",
       "   4113,\n",
       "   2282,\n",
       "   2160,\n",
       "   1029,\n",
       "   100,\n",
       "   2077,\n",
       "   1045,\n",
       "   10797,\n",
       "   1045,\n",
       "   2031,\n",
       "   1037,\n",
       "   2261,\n",
       "   3980,\n",
       "   1012,\n",
       "   2054,\n",
       "   2181,\n",
       "   2003,\n",
       "   1996,\n",
       "   3309,\n",
       "   2284,\n",
       "   1999,\n",
       "   1029,\n",
       "   100,\n",
       "   1996,\n",
       "   3309,\n",
       "   2003,\n",
       "   1999,\n",
       "   1996,\n",
       "   2148,\n",
       "   2181,\n",
       "   1012,\n",
       "   100,\n",
       "   2079,\n",
       "   2027,\n",
       "   2031,\n",
       "   2393,\n",
       "   2005,\n",
       "   9776,\n",
       "   5581,\n",
       "   1029,\n",
       "   100,\n",
       "   2748,\n",
       "   1012,\n",
       "   2023,\n",
       "   3200,\n",
       "   2038,\n",
       "   7801,\n",
       "   5581,\n",
       "   1012,\n",
       "   2151,\n",
       "   2060,\n",
       "   3160,\n",
       "   1029,\n",
       "   100,\n",
       "   2003,\n",
       "   1037,\n",
       "   9425,\n",
       "   4003,\n",
       "   11701,\n",
       "   2005,\n",
       "   2023,\n",
       "   21725,\n",
       "   1029,\n",
       "   100,\n",
       "   2958,\n",
       "   4113,\n",
       "   2160,\n",
       "   1026,\n",
       "   3716,\n",
       "   1035,\n",
       "   19802,\n",
       "   1028,\n",
       "   2054,\n",
       "   7909,\n",
       "   7047,\n",
       "   2024,\n",
       "   3970,\n",
       "   2012,\n",
       "   2958,\n",
       "   4113,\n",
       "   2160,\n",
       "   1029,\n",
       "   1026,\n",
       "   3716,\n",
       "   1035,\n",
       "   19802,\n",
       "   1028,\n",
       "   9425,\n",
       "   1998,\n",
       "   3040,\n",
       "   11522,\n",
       "   2024,\n",
       "   3970,\n",
       "   2012,\n",
       "   2958,\n",
       "   4113,\n",
       "   2160,\n",
       "   100],\n",
       "  [100,\n",
       "   100,\n",
       "   2833,\n",
       "   1999,\n",
       "   2568,\n",
       "   1029,\n",
       "   100,\n",
       "   1045,\n",
       "   1005,\n",
       "   1040,\n",
       "   2066,\n",
       "   2000,\n",
       "   2031,\n",
       "   2070,\n",
       "   2822,\n",
       "   2833,\n",
       "   1012,\n",
       "   100,\n",
       "   2008,\n",
       "   25142,\n",
       "   2091,\n",
       "   1996,\n",
       "   4825,\n",
       "   9804,\n",
       "   2000,\n",
       "   2184,\n",
       "   1012,\n",
       "   2003,\n",
       "   2045,\n",
       "   1037,\n",
       "   3976,\n",
       "   2846,\n",
       "   2017,\n",
       "   2052,\n",
       "   2066,\n",
       "   2000,\n",
       "   2994,\n",
       "   1999,\n",
       "   1029,\n",
       "   100,\n",
       "   1045,\n",
       "   2572,\n",
       "   2559,\n",
       "   2005,\n",
       "   1037,\n",
       "   17844,\n",
       "   21125,\n",
       "   2173,\n",
       "   2000,\n",
       "   4521,\n",
       "   1010,\n",
       "   1045,\n",
       "   2572,\n",
       "   2036,\n",
       "   2559,\n",
       "   2000,\n",
       "   2338,\n",
       "   1037,\n",
       "   2282,\n",
       "   1999,\n",
       "   1996,\n",
       "   2958,\n",
       "   4113,\n",
       "   2160,\n",
       "   3309,\n",
       "   1012,\n",
       "   100,\n",
       "   2029,\n",
       "   5246,\n",
       "   2097,\n",
       "   2017,\n",
       "   2022,\n",
       "   6595,\n",
       "   2012,\n",
       "   1996,\n",
       "   2958,\n",
       "   4113,\n",
       "   2282,\n",
       "   2160,\n",
       "   1029,\n",
       "   100,\n",
       "   2077,\n",
       "   1045,\n",
       "   10797,\n",
       "   1045,\n",
       "   2031,\n",
       "   1037,\n",
       "   2261,\n",
       "   3980,\n",
       "   1012,\n",
       "   2054,\n",
       "   2181,\n",
       "   2003,\n",
       "   1996,\n",
       "   3309,\n",
       "   2284,\n",
       "   1999,\n",
       "   1029,\n",
       "   100,\n",
       "   1996,\n",
       "   3309,\n",
       "   2003,\n",
       "   1999,\n",
       "   1996,\n",
       "   2148,\n",
       "   2181,\n",
       "   1012,\n",
       "   100,\n",
       "   2079,\n",
       "   2027,\n",
       "   2031,\n",
       "   2393,\n",
       "   2005,\n",
       "   9776,\n",
       "   5581,\n",
       "   1029,\n",
       "   100,\n",
       "   2748,\n",
       "   1012,\n",
       "   2023,\n",
       "   3200,\n",
       "   2038,\n",
       "   7801,\n",
       "   5581,\n",
       "   1012,\n",
       "   2151,\n",
       "   2060,\n",
       "   3160,\n",
       "   1029,\n",
       "   100,\n",
       "   2003,\n",
       "   1037,\n",
       "   9425,\n",
       "   4003,\n",
       "   11701,\n",
       "   2005,\n",
       "   2023,\n",
       "   21725,\n",
       "   1029,\n",
       "   100,\n",
       "   2175,\n",
       "   2078,\n",
       "   3077,\n",
       "   3309,\n",
       "   1026,\n",
       "   3716,\n",
       "   1035,\n",
       "   19802,\n",
       "   1028,\n",
       "   2515,\n",
       "   2115,\n",
       "   3309,\n",
       "   2031,\n",
       "   1037,\n",
       "   12403,\n",
       "   1029,\n",
       "   1026,\n",
       "   3716,\n",
       "   1035,\n",
       "   19802,\n",
       "   1028,\n",
       "   2045,\n",
       "   2003,\n",
       "   1037,\n",
       "   12403,\n",
       "   2006,\n",
       "   28032,\n",
       "   2063,\n",
       "   2012,\n",
       "   1996,\n",
       "   2175,\n",
       "   2078,\n",
       "   3077,\n",
       "   3309,\n",
       "   1012,\n",
       "   100],\n",
       "  [100,\n",
       "   100,\n",
       "   2833,\n",
       "   1999,\n",
       "   2568,\n",
       "   1029,\n",
       "   100,\n",
       "   1045,\n",
       "   1005,\n",
       "   1040,\n",
       "   2066,\n",
       "   2000,\n",
       "   2031,\n",
       "   2070,\n",
       "   2822,\n",
       "   2833,\n",
       "   1012,\n",
       "   100,\n",
       "   2008,\n",
       "   25142,\n",
       "   2091,\n",
       "   1996,\n",
       "   4825,\n",
       "   9804,\n",
       "   2000,\n",
       "   2184,\n",
       "   1012,\n",
       "   2003,\n",
       "   2045,\n",
       "   1037,\n",
       "   3976,\n",
       "   2846,\n",
       "   2017,\n",
       "   2052,\n",
       "   2066,\n",
       "   2000,\n",
       "   2994,\n",
       "   1999,\n",
       "   1029,\n",
       "   100,\n",
       "   1045,\n",
       "   2572,\n",
       "   2559,\n",
       "   2005,\n",
       "   1037,\n",
       "   17844,\n",
       "   21125,\n",
       "   2173,\n",
       "   2000,\n",
       "   4521,\n",
       "   1010,\n",
       "   1045,\n",
       "   2572,\n",
       "   2036,\n",
       "   2559,\n",
       "   2000,\n",
       "   2338,\n",
       "   1037,\n",
       "   2282,\n",
       "   1999,\n",
       "   1996,\n",
       "   2958,\n",
       "   4113,\n",
       "   2160,\n",
       "   3309,\n",
       "   1012,\n",
       "   100,\n",
       "   2029,\n",
       "   5246,\n",
       "   2097,\n",
       "   2017,\n",
       "   2022,\n",
       "   6595,\n",
       "   2012,\n",
       "   1996,\n",
       "   2958,\n",
       "   4113,\n",
       "   2282,\n",
       "   2160,\n",
       "   1029,\n",
       "   100,\n",
       "   2077,\n",
       "   1045,\n",
       "   10797,\n",
       "   1045,\n",
       "   2031,\n",
       "   1037,\n",
       "   2261,\n",
       "   3980,\n",
       "   1012,\n",
       "   2054,\n",
       "   2181,\n",
       "   2003,\n",
       "   1996,\n",
       "   3309,\n",
       "   2284,\n",
       "   1999,\n",
       "   1029,\n",
       "   100,\n",
       "   1996,\n",
       "   3309,\n",
       "   2003,\n",
       "   1999,\n",
       "   1996,\n",
       "   2148,\n",
       "   2181,\n",
       "   1012,\n",
       "   100,\n",
       "   2079,\n",
       "   2027,\n",
       "   2031,\n",
       "   2393,\n",
       "   2005,\n",
       "   9776,\n",
       "   5581,\n",
       "   1029,\n",
       "   100,\n",
       "   2748,\n",
       "   1012,\n",
       "   2023,\n",
       "   3200,\n",
       "   2038,\n",
       "   7801,\n",
       "   5581,\n",
       "   1012,\n",
       "   2151,\n",
       "   2060,\n",
       "   3160,\n",
       "   1029,\n",
       "   100,\n",
       "   2003,\n",
       "   1037,\n",
       "   9425,\n",
       "   4003,\n",
       "   11701,\n",
       "   2005,\n",
       "   2023,\n",
       "   21725,\n",
       "   1029,\n",
       "   100,\n",
       "   2958,\n",
       "   4113,\n",
       "   2160,\n",
       "   1026,\n",
       "   3716,\n",
       "   1035,\n",
       "   19802,\n",
       "   1028,\n",
       "   2079,\n",
       "   2017,\n",
       "   3073,\n",
       "   2151,\n",
       "   14533,\n",
       "   2578,\n",
       "   1029,\n",
       "   1026,\n",
       "   3716,\n",
       "   1035,\n",
       "   19802,\n",
       "   1028,\n",
       "   14533,\n",
       "   2578,\n",
       "   2024,\n",
       "   3024,\n",
       "   2182,\n",
       "   1012,\n",
       "   100]],\n",
       " 'token_type_ids': [[0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1]],\n",
       " 'mc_token_ids': [173, 175, 166],\n",
       " 'candidate_keys': ['hotel__11__0',\n",
       "  'hotel__11__1',\n",
       "  'hotel__11__2',\n",
       "  'hotel__11__3',\n",
       "  'hotel__11__4',\n",
       "  'hotel__11__5',\n",
       "  'hotel__11__6',\n",
       "  'hotel__11__7',\n",
       "  'hotel__11__8',\n",
       "  'hotel__11__9',\n",
       "  'hotel__11__10',\n",
       "  'hotel__11__11',\n",
       "  'hotel__11__12',\n",
       "  'hotel__11__13',\n",
       "  'hotel__11__14',\n",
       "  'hotel__11__15',\n",
       "  'hotel__11__16',\n",
       "  'hotel__11__17',\n",
       "  'hotel__11__18',\n",
       "  'hotel__11__19',\n",
       "  'hotel__11__20',\n",
       "  'hotel__11__21',\n",
       "  'hotel__11__22',\n",
       "  'hotel__11__23',\n",
       "  'hotel__11__24',\n",
       "  'hotel__11__25',\n",
       "  'hotel__11__26',\n",
       "  'hotel__11__27',\n",
       "  'hotel__11__28',\n",
       "  'hotel__11__29',\n",
       "  'hotel__11__30',\n",
       "  'hotel__11__31',\n",
       "  'hotel__11__32',\n",
       "  'hotel__11__33',\n",
       "  'hotel__11__34',\n",
       "  'hotel__11__35',\n",
       "  'hotel__11__36',\n",
       "  'hotel__11__37',\n",
       "  'hotel__21__5',\n",
       "  'restaurant__19248__8',\n",
       "  'restaurant__19192__10',\n",
       "  'hotel__26__19',\n",
       "  'hotel__27__27',\n",
       "  'restaurant__19262__11',\n",
       "  'restaurant__31390__12',\n",
       "  'restaurant__19237__4',\n",
       "  'hotel__10__30',\n",
       "  'restaurant__19255__0',\n",
       "  'hotel__31__31',\n",
       "  'hotel__6__19',\n",
       "  'restaurant__19251__14',\n",
       "  'restaurant__19263__12',\n",
       "  'restaurant__19222__12',\n",
       "  'hotel__28__16',\n",
       "  'restaurant__19255__4',\n",
       "  'hotel__13__11',\n",
       "  'restaurant__19180__6',\n",
       "  'hotel__9__8',\n",
       "  'restaurant__31390__7',\n",
       "  'restaurant__4607__8',\n",
       "  'hotel__23__27',\n",
       "  'restaurant__19196__6',\n",
       "  'restaurant__19251__3',\n",
       "  'hotel__2__19',\n",
       "  'restaurant__19176__0',\n",
       "  'hotel__18__1',\n",
       "  'restaurant__19262__5',\n",
       "  'hotel__31__28',\n",
       "  'hotel__30__9',\n",
       "  'restaurant__7492__4',\n",
       "  'restaurant__19227__6',\n",
       "  'restaurant__19196__11',\n",
       "  'restaurant__19176__7',\n",
       "  'hotel__27__33',\n",
       "  'restaurant__19187__6',\n",
       "  'hotel__14__23'],\n",
       " 'label_idx': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[  100,   100,  2833,  1999,  2568,  1029,   100,  1045,  1005,  1040,\n",
       "            2066,  2000,  2031,  2070,  2822,  2833,  1012,   100,  2008, 25142,\n",
       "            2091,  1996,  4825,  9804,  2000,  2184,  1012,  2003,  2045,  1037,\n",
       "            3976,  2846,  2017,  2052,  2066,  2000,  2994,  1999,  1029,   100,\n",
       "            1045,  2572,  2559,  2005,  1037, 17844, 21125,  2173,  2000,  4521,\n",
       "            1010,  1045,  2572,  2036,  2559,  2000,  2338,  1037,  2282,  1999,\n",
       "            1996,  2958,  4113,  2160,  3309,  1012,   100,  2029,  5246,  2097,\n",
       "            2017,  2022,  6595,  2012,  1996,  2958,  4113,  2282,  2160,  1029,\n",
       "             100,  2077,  1045, 10797,  1045,  2031,  1037,  2261,  3980,  1012,\n",
       "            2054,  2181,  2003,  1996,  3309,  2284,  1999,  1029,   100,  1996,\n",
       "            3309,  2003,  1999,  1996,  2148,  2181,  1012,   100,  2079,  2027,\n",
       "            2031,  2393,  2005,  9776,  5581,  1029,   100,  2748,  1012,  2023,\n",
       "            3200,  2038,  7801,  5581,  1012,  2151,  2060,  3160,  1029,   100,\n",
       "            2003,  1037,  9425,  4003, 11701,  2005,  2023, 21725,  1029,   100,\n",
       "            2958,  4113,  2160,  1026,  3716,  1035, 19802,  1028,  2079,  1045,\n",
       "            2031,  2000,  3477,  2005,  5581,  1029,  1026,  3716,  1035, 19802,\n",
       "            1028,  2958,  4113,  2160,  2038,  2489,  5581,  1012,   100,   100,\n",
       "             100,   100,   100,   100,   100,   100,   100],\n",
       "          [  100,   100,  2833,  1999,  2568,  1029,   100,  1045,  1005,  1040,\n",
       "            2066,  2000,  2031,  2070,  2822,  2833,  1012,   100,  2008, 25142,\n",
       "            2091,  1996,  4825,  9804,  2000,  2184,  1012,  2003,  2045,  1037,\n",
       "            3976,  2846,  2017,  2052,  2066,  2000,  2994,  1999,  1029,   100,\n",
       "            1045,  2572,  2559,  2005,  1037, 17844, 21125,  2173,  2000,  4521,\n",
       "            1010,  1045,  2572,  2036,  2559,  2000,  2338,  1037,  2282,  1999,\n",
       "            1996,  2958,  4113,  2160,  3309,  1012,   100,  2029,  5246,  2097,\n",
       "            2017,  2022,  6595,  2012,  1996,  2958,  4113,  2282,  2160,  1029,\n",
       "             100,  2077,  1045, 10797,  1045,  2031,  1037,  2261,  3980,  1012,\n",
       "            2054,  2181,  2003,  1996,  3309,  2284,  1999,  1029,   100,  1996,\n",
       "            3309,  2003,  1999,  1996,  2148,  2181,  1012,   100,  2079,  2027,\n",
       "            2031,  2393,  2005,  9776,  5581,  1029,   100,  2748,  1012,  2023,\n",
       "            3200,  2038,  7801,  5581,  1012,  2151,  2060,  3160,  1029,   100,\n",
       "            2003,  1037,  9425,  4003, 11701,  2005,  2023, 21725,  1029,   100,\n",
       "            2958,  4113,  2160,  1026,  3716,  1035, 19802,  1028,  2054,  7909,\n",
       "            7047,  2024,  3970,  2012,  2958,  4113,  2160,  1029,  1026,  3716,\n",
       "            1035, 19802,  1028,  9425,  1998,  3040, 11522,  2024,  3970,  2012,\n",
       "            2958,  4113,  2160,   100,   100,   100,   100],\n",
       "          [  100,   100,  2833,  1999,  2568,  1029,   100,  1045,  1005,  1040,\n",
       "            2066,  2000,  2031,  2070,  2822,  2833,  1012,   100,  2008, 25142,\n",
       "            2091,  1996,  4825,  9804,  2000,  2184,  1012,  2003,  2045,  1037,\n",
       "            3976,  2846,  2017,  2052,  2066,  2000,  2994,  1999,  1029,   100,\n",
       "            1045,  2572,  2559,  2005,  1037, 17844, 21125,  2173,  2000,  4521,\n",
       "            1010,  1045,  2572,  2036,  2559,  2000,  2338,  1037,  2282,  1999,\n",
       "            1996,  2958,  4113,  2160,  3309,  1012,   100,  2029,  5246,  2097,\n",
       "            2017,  2022,  6595,  2012,  1996,  2958,  4113,  2282,  2160,  1029,\n",
       "             100,  2077,  1045, 10797,  1045,  2031,  1037,  2261,  3980,  1012,\n",
       "            2054,  2181,  2003,  1996,  3309,  2284,  1999,  1029,   100,  1996,\n",
       "            3309,  2003,  1999,  1996,  2148,  2181,  1012,   100,  2079,  2027,\n",
       "            2031,  2393,  2005,  9776,  5581,  1029,   100,  2748,  1012,  2023,\n",
       "            3200,  2038,  7801,  5581,  1012,  2151,  2060,  3160,  1029,   100,\n",
       "            2003,  1037,  9425,  4003, 11701,  2005,  2023, 21725,  1029,   100,\n",
       "            2958,  4113,  2160,  1026,  3716,  1035, 19802,  1028,  2024,  2045,\n",
       "            2151, 10516,  2415,  2030,  9726,  1029,  1026,  3716,  1035, 19802,\n",
       "            1028,  2958,  4113,  2160,  2515,  2025,  2031,  1037, 10516,  2415,\n",
       "            2030,  9726,  2006, 28032,  2063,  1012,   100]]]),\n",
       " tensor([[[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "             1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "             1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "             1, 100, 100, 100, 100, 100, 100, 100, 100],\n",
       "          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "             1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "             1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "             1,   1,   1,   1,   1,   1, 100, 100, 100],\n",
       "          [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "             0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   1,\n",
       "             1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "             1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
       "             1,   1,   1,   1,   1,   1,   1,   1,   1]]]),\n",
       " tensor([[168, 173, 176]]),\n",
       " tensor([[[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100],\n",
       "          [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100],\n",
       "          [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "           -100]]]),\n",
       " tensor([1]),\n",
       " {'dialog_ids': [5],\n",
       "  'candidate_keys': [['hotel__11__0',\n",
       "    'hotel__11__1',\n",
       "    'hotel__11__2',\n",
       "    'hotel__11__3',\n",
       "    'hotel__11__4',\n",
       "    'hotel__11__5',\n",
       "    'hotel__11__6',\n",
       "    'hotel__11__7',\n",
       "    'hotel__11__8',\n",
       "    'hotel__11__9',\n",
       "    'hotel__11__10',\n",
       "    'hotel__11__11',\n",
       "    'hotel__11__12',\n",
       "    'hotel__11__13',\n",
       "    'hotel__11__14',\n",
       "    'hotel__11__15',\n",
       "    'hotel__11__16',\n",
       "    'hotel__11__17',\n",
       "    'hotel__11__18',\n",
       "    'hotel__11__19',\n",
       "    'hotel__11__20',\n",
       "    'hotel__11__21',\n",
       "    'hotel__11__22',\n",
       "    'hotel__11__23',\n",
       "    'hotel__11__24',\n",
       "    'hotel__11__25',\n",
       "    'hotel__11__26',\n",
       "    'hotel__11__27',\n",
       "    'hotel__11__28',\n",
       "    'hotel__11__29',\n",
       "    'hotel__11__30',\n",
       "    'hotel__11__31',\n",
       "    'hotel__11__32',\n",
       "    'hotel__11__33',\n",
       "    'hotel__11__34',\n",
       "    'hotel__11__35',\n",
       "    'hotel__11__36',\n",
       "    'hotel__11__37',\n",
       "    'hotel__32__24',\n",
       "    'restaurant__19240__0',\n",
       "    'restaurant__19269__5',\n",
       "    'restaurant__19183__14',\n",
       "    'hotel__32__12',\n",
       "    'restaurant__19213__9',\n",
       "    'hotel__28__2',\n",
       "    'hotel__15__17',\n",
       "    'hotel__2__14',\n",
       "    'restaurant__19182__1',\n",
       "    'hotel__24__33',\n",
       "    'restaurant__12238__3',\n",
       "    'restaurant__19272__5',\n",
       "    'restaurant__19261__3',\n",
       "    'hotel__13__16',\n",
       "    'restaurant__19213__4',\n",
       "    'restaurant__19256__12',\n",
       "    'hotel__4__26',\n",
       "    'hotel__26__0',\n",
       "    'hotel__28__4',\n",
       "    'restaurant__19231__3',\n",
       "    'restaurant__19237__1',\n",
       "    'hotel__24__34',\n",
       "    'restaurant__19172__14',\n",
       "    'hotel__26__33',\n",
       "    'restaurant__7492__6',\n",
       "    'restaurant__19192__9',\n",
       "    'hotel__22__27',\n",
       "    'restaurant__19211__13',\n",
       "    'hotel__8__25',\n",
       "    'restaurant__12566__14',\n",
       "    'restaurant__31390__5',\n",
       "    'restaurant__19257__2',\n",
       "    'restaurant__19176__6',\n",
       "    'hotel__2__2',\n",
       "    'restaurant__19226__8',\n",
       "    'hotel__31__20',\n",
       "    'hotel__1__21']]})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.collate_fn([train_dataset[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['history', 'knowledge', 'candidates', 'response', 'response_text', 'label', 'knowledge_seeking', 'dialog_id'])\n",
      "\n",
      "history\n",
      "[[2833, 1999, 2568, 1029], [1045, 1005, 1040, 2066, 2000, 2031, 2070, 2822, 2833, 1012], [2008, 25142, 2091, 1996, 4825, 9804, 2000, 2184, 1012, 2003, 2045, 1037, 3976, 2846, 2017, 2052, 2066, 2000, 2994, 1999, 1029], [1045, 2572, 2559, 2005, 1037, 17844, 21125, 2173, 2000, 4521, 1010, 1045, 2572, 2036, 2559, 2000, 2338, 1037, 2282, 1999, 1996, 2958, 4113, 2160, 3309, 1012], [2029, 5246, 2097, 2017, 2022, 6595, 2012, 1996, 2958, 4113, 2282, 2160, 1029], [2077, 1045, 10797, 1045, 2031, 1037, 2261, 3980, 1012, 2054, 2181, 2003, 1996, 3309, 2284, 1999, 1029], [1996, 3309, 2003, 1999, 1996, 2148, 2181, 1012], [2079, 2027, 2031, 2393, 2005, 9776, 5581, 1029], [2748, 1012, 2023, 3200, 2038, 7801, 5581, 1012, 2151, 2060, 3160, 1029], [2003, 1037, 9425, 4003, 11701, 2005, 2023, 21725, 1029]]\n",
      "\n",
      "knowledge\n",
      "[2958, 4113, 2160, 1026, 3716, 1035, 19802, 1028, 2054, 7909, 7047, 2024, 3970, 2012, 2958, 4113, 2160, 1029, 1026, 3716, 1035, 19802, 1028, 9425, 1998, 3040, 11522, 2024, 3970, 2012, 2958, 4113, 2160]\n",
      "\n",
      "candidates\n",
      "['hotel__11__0', 'hotel__11__1', 'hotel__11__2', 'hotel__11__3', 'hotel__11__4', 'hotel__11__5', 'hotel__11__6', 'hotel__11__7', 'hotel__11__8', 'hotel__11__9', 'hotel__11__10', 'hotel__11__11', 'hotel__11__12', 'hotel__11__13', 'hotel__11__14', 'hotel__11__15', 'hotel__11__16', 'hotel__11__17', 'hotel__11__18', 'hotel__11__19', 'hotel__11__20', 'hotel__11__21', 'hotel__11__22', 'hotel__11__23', 'hotel__11__24', 'hotel__11__25', 'hotel__11__26', 'hotel__11__27', 'hotel__11__28', 'hotel__11__29', 'hotel__11__30', 'hotel__11__31', 'hotel__11__32', 'hotel__11__33', 'hotel__11__34', 'hotel__11__35', 'hotel__11__36', 'hotel__11__37']\n",
      "\n",
      "response\n",
      "[2748, 1010, 1996, 2958, 4113, 2160, 13385, 9425, 1998, 3040, 11522, 2004, 1037, 2433, 1997, 7909, 1012, 2079, 2017, 2031, 2151, 2062, 3980, 1029]\n",
      "\n",
      "response_text\n",
      "Yes, The Bridge Guest House accepts Visa and Mastercard as a form of payment. Do you have any more questions?\n",
      "\n",
      "label\n",
      "{'target': True, 'knowledge': [{'domain': 'hotel', 'entity_id': 11, 'doc_id': 13}], 'response': 'Yes, The Bridge Guest House accepts Visa and Mastercard as a form of payment. Do you have any more questions?', 'response_tokenized': [2748, 1010, 1996, 2958, 4113, 2160, 13385, 9425, 1998, 3040, 11522, 2004, 1037, 2433, 1997, 7909, 1012, 2079, 2017, 2031, 2151, 2062, 3980, 1029]}\n",
      "\n",
      "knowledge_seeking\n",
      "True\n",
      "\n",
      "dialog_id\n",
      "5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.examples[1].keys())\n",
    "print()\n",
    "for key in train_dataset.examples[1].keys():\n",
    "    print(key)\n",
    "    print(train_dataset.examples[1][key])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bridge guest house < knowledge _ sep > are pets allowed here ? < knowledge _ sep > no , pets are not allowed at this property .'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(tokenizer.convert_ids_to_tokens(train_dataset.snippets[\"hotel__11__0\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track 2 : Response generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseGenerationDataset(BaseDataset):\n",
    "    def __init__(self, args, tokenizer, split_type, labels=True, labels_file=None):\n",
    "        super(ResponseGenerationDataset, self).__init__(args, tokenizer, split_type, labels, labels_file)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        example = self.examples[index]\n",
    "        instance, _ = self.build_input_from_segments(\n",
    "            example[\"knowledge\"],\n",
    "            example[\"history\"],\n",
    "            example[\"response\"]\n",
    "        )\n",
    "        return instance\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        input_ids = [ins[\"input_ids\"] for ins in batch]\n",
    "        token_type_ids = [ins[\"token_type_ids\"] for ins in batch]\n",
    "        lm_labels = [ins[\"lm_labels\"] for ins in batch]\n",
    "\n",
    "        input_ids = torch.tensor(pad_ids(input_ids, self.pad))\n",
    "        token_type_ids = torch.tensor(pad_ids(token_type_ids, self.pad))\n",
    "        lm_labels = torch.tensor(pad_ids(lm_labels, -100))\n",
    "\n",
    "        return input_ids, token_type_ids, lm_labels\n",
    "\n",
    "\n",
    "class ResponseGenerationEvalDataset(BaseDataset):\n",
    "    def __init__(self, args, tokenizer, split_type, labels=True, labels_file=None):\n",
    "        super(ResponseGenerationEvalDataset, self).__init__(args, tokenizer, split_type, labels, labels_file)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        example = self.examples[index]\n",
    "        return example\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.task = \"generation\"\n",
    "args.labels_file = \"data/val/labels.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bd2d65134b749208545069b36797fd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=72518.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "086d23eb6db442b19f2f4d405fd8951a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=72518.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generation_datset = ResponseGenerationDataset(args, tokenizer, split_type=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'mc_token_ids', 'lm_labels'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_datset[1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e7a996941b453bbd221c488d381ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfa3bde2e8ec4932a23a0bef27f2063b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generation_eval_datset = ResponseGenerationEvalDataset(args, tokenizer, split_type=\"val\",\n",
    "                                                      labels_file=args.labels_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['history', 'knowledge', 'candidates', 'response', 'response_text', 'label', 'knowledge_seeking', 'dialog_id'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_eval_datset[1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
